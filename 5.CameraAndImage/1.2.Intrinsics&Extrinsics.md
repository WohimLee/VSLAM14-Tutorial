&emsp;
# Intrinsics and Extrinsics


# 1 相机内参（Camera Intrinsics）$\pmb{K}$
- 即投影成像的过程
  
把该式写成矩阵形式，会更加简洁，不过左侧需要用到齐次坐标：
$$\begin{pmatrix}u \\ v \\ 1\end{pmatrix} = 
\frac{1}{Z}
\begin{pmatrix}f_x & 0 & c_x \\
0 & f_y & c_y \\
0 & 0 & 1\end{pmatrix}
\begin{pmatrix} X \\ Y \\ Z\end{pmatrix}
\triangleq \frac{1}{Z}\pmb{KP}$$

我们按照传统的习惯，把 $Z$ 挪到左侧：

$$Z\begin{pmatrix}u \\ v \\ 1\end{pmatrix} = 
\begin{pmatrix}f_x & 0 & c_x \\
0 & f_y & c_y \\
0 & 0 & 1\end{pmatrix}
\begin{pmatrix} X \\ Y \\ Z\end{pmatrix}
\triangleq \pmb{KP}$$

该式中，我们把中间的量组成的矩阵称为相机的 `内参数矩阵（Camera Intrinsics）`$\pmb{K}$


>相机标定
- 通常认为，相机的内参在出厂之后是固定的，不会在使用过程中发生变化。有的相机生产厂商会告诉你相机的内参，而有时需要你自己确定相机的内参，也就是所谓的标定
- 张正友标定

&emsp;
# 2 相机外参（Camera Extrinsics）$\pmb{T}_{CW}$
- 即坐标系的转换


前面例子的转换过程我们其实默认了一点：$X，Y，Z$ 使用的是 $P$ 在相机坐标系下的坐标，而且没有考虑运动状态

现在，我们完善一下这个过程：
- 把第 1 帧的相机坐标系定为世界坐标
- $P$ 的坐标是 `世界坐标`（记为 $P_W$）
- 相机在运动，我们要求当前帧的像素坐标 $(u, v)$


相机的位姿由它的旋转矩阵 $\pmb{R}$ 和平移向量 $\pmb{t}$ 来描述。那么有：

$$(\pmb{R}_{CW}P_{W} + \pmb{t})  =\pmb{T}_{CW}\pmb{P}_{W}$$

所以我们应该先把世界坐标系转换成当前的相机坐标系，再将相机坐标系转换成像素坐标：
$$\pmb{P}_{uv} = \begin{bmatrix}u \\ v \\ 1\end{bmatrix} = 
\frac{1}{Z}\pmb{K}(\pmb{R}P_W + \pmb{t}) = 
\frac{1}{Z}\pmb{KT}_{CW}P_W$$


它描述了 $P$ 的世界坐标到像素坐标的投影关系。其中，相机的位姿 $\pmb{R}， \pmb{t}$ 又称为相机的 `外参数（Camera Extrinsics）`

相比于不变的内参，外参会随着相机运动发生改变，同时也是 SLAM 中待估计的目标，代表着机器人的轨迹


&emsp;
# 3 常见的坐标转换
## 3.1 世界坐标 -> 像素坐标
- 世界坐标 -> 相机坐标 -> 像素坐标（归一化/齐次坐标）
    $$P_{uv} = 
    \frac{1}{Z}\pmb{K}\pmb{T}_{CW}P_W
    \Rightarrow 
    \begin{bmatrix}u \\ v \\ 1\end{bmatrix} = 
    \frac{1}{Z}\begin{bmatrix}
    f_x & 0 & c_x \\
    0 & f_y & c_y \\
    0 & 0   & 1
    \end{bmatrix}
    \pmb{T}_{CW}
    \begin{bmatrix} X_W \\ Y_W \\ Z_W\end{bmatrix}$$
>code: world2pixel
```py
import numpy as np

def getIntrinsicMatrix(fx=500, fy=500, cx=320, cy=240):
    '''
    Get Intrinsic Matrix K
    Parameters:
        fx: Focal length along the x-axis
        fy: Focal length along the y-axis
        cx: Principal point x-coordinate
        cy: Principal point y-coordinate
    '''
    # Camera instrinsic matrix K
    K = np.array([[fx, 0 , cx],
                [0 , fy, cy],
                [0 , 0 , 1 ]])
    return K

def getTransformMatrix(R, t):
    # Convert to homogeneous coordinates
    vec = np.array([0,0,0,1])
    T   = np.vstack((np.hstack((R, t)), vec))
    return T

def world2camera(Pw, Tcw):
    # Convert to homogeneous coordinates
    P_homogeneous = np.append(Pw, 1) 
    # 1 World to camera (homogenous coordinates)
    Pc  = Tcw @ P_homogeneous
    return Pc

def camera2pixel(Pc, K):
    # 2 Camera to pixel
    Puv = K @ Pc[:3]
    Puv = Puv[:2] / Puv[2]
    return Puv.astype(np.int8)
    
if __name__ == '__main__':
    # Camera extrinsic parameters (rotation matrix and translation vector)
    R = np.array([[0.8660254, -0.5     , 0],
                [0.5      , 0.8660254, 0],
                [0        , 0        , 1]])
    t = np.array([1, 2, 3]).reshape(3, 1)

    K   = getIntrinsicMatrix()
    Tcw = getTransformMatrix(R, t)

    Pw  = np.array([2, 4, 6])
    Pc  = world2camera(Pw, Tcw)
    Puv = camera2pixel(Pc, K)
    print("Pw : (X, Y, Z) = ({},{},{})".format(*Pw))
    print("to:")
    print("Pc : (X, Y, Z) = ({},{},{})".format(*Pc))
    print("Puv: (u, v)    = ({},{})".format(*Puv))
    print("\n")
```


&emsp;
## 3.2 像素坐标 -> 世界坐标
像素坐标 -> 相机坐标 -> 世界坐标
- 像素坐标 -> 相机坐标
  - 需要知道深度 $Z$（depth）
  - 再根据上述式子，求 $X，Y$
      $$P_{Camera} = \begin{bmatrix} X_C \\ Y_C \\ Z_C\end{bmatrix} = Z\cdot \pmb{K}^{-1}P_{uv}$$
- 相机坐标 -> 世界坐标
$$P_{World} = T_{CW}^{-1}P_{Camera} = T_{WC}P_{Camera}$$

>code: pixel2world
```py
import numpy as np

def genIntrinsicMatrix(fx=500, fy=500, cx=320, cy=240):
    '''
    Get Intrinsic Matrix K
    Parameters:
        fx: Focal length along the x-axis
        fy: Focal length along the y-axis
        cx: Principal point x-coordinate
        cy: Principal point y-coordinate
    '''
    # Camera instrinsic matrix K
    K = np.array([[fx, 0 , cx],
                [0 , fy, cy],
                [0 , 0 , 1 ]])
    return K

def getTransformMatrix(R, t):
    # Convert to homogeneous coordinates
    vec = np.array([0,0,0,1])
    T   = np.vstack((np.hstack((R, t)), vec))
    return T


def pixel2camera(pixel, depth, K):
    # Convert to homogenous coordinates
    P_homogenous = np.append(pixel, 1)
    Pc = depth * np.linalg.inv(K) @ P_homogenous
    return Pc

def camera2world(Pc, Twc):
    # Convert to homogenous coordinates
    P_homogenous = np.append(Pc, 1)
    Pw = Twc @ P_homogenous
    Pw = Pw[:3] / Pw[3]
    return Pw



if __name__ == '__main__':
    pixel = np.array([360.6694888888889, 599.1167555555555]).astype(np.i    nt8)
    depth = 9 # Zc
    K     = genIntrinsicMatrix()

    # Camera extrinsic parameters (rotation matrix and translation vector)
    R = np.array([[0.8660254, -0.5     , 0],
                [0.5      , 0.8660254, 0],
                [0        , 0        , 1]])
    t = np.array([1, 2, 3]).reshape(3, 1)

    Tcw = getTransformMatrix(R, t)
    Twc = np.linalg.inv(Tcw)
    Pc = pixel2camera(pixel, depth, K)
    Pw = camera2world(Pc, Twc)
    print("Puv: (u, v)    = ({},{})".format(*pixel))
    print("to: ")
    print("Pc : (X, Y, Z) = ({},{},{})".format(*Pc))
    print("Pw : (X, Y, Z) = ({},{},{})".format(*Pw))
    print("\n")
```     
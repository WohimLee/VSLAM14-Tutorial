&emsp;
# 双目相机模型 Binocular

# 1 Intro
针孔相机模型描述了单个相机的成像模型


然而，仅根据一个像素，我们是无法确定这个空间点的具体位置的。这是因为，从相机光心到归一化平面连线上的所有点，都可以投影至该像素上。只有当 $P$ 的深度确定时（比如通过双目或 RGB-D 相机），我们才能确切地知道它的空间位置

<div align="center">
    <image src="./imgs/5.1.2-3.png" width = 800>
</div>
&emsp;

测量像素距离（或深度）的方式有很多种，像人眼就可以根据左右眼看到的景物差异（或称视差）来判断物体与我们的距离

双目相机的原理亦是如此。通过同步采集左右相机的图像，计算图像间视差，来估计每一个像素的深度



&emsp;
# 2 建模过程
双目相机一般由左眼和右眼两个水平放置的相机组成。当然也可以做成上下两个目，但我们见到的主流双目都是做成左右的

<div align="center">
    <image src="./imgs/5.1.3-1.png" width = 800>
</div>
&emsp;


>基线（Baseline, 记作 b）
- 在左右双目的相机中，我们可以把两个相机都看作针孔相机。它们是水平放置的，意味两个相机的光圈中心都位于 $x$ 轴上。它们的距离称为双目相机的 `基线（Baseline, 记作 b）`，是双目的重要参数。

现在，考虑一个空间点 $P$，它在左眼和右眼各成一像，记作 $P_L， P_R$。由于相机基线的存在，这两个成像位置是不同的。理想情况下，由于左右相机只有在 $x$ 轴上有位移，因此 $P$ 的像也只在 $x$ 轴（对应图像的 $u$ 轴）上有差异。我们记它在左侧的坐标为 $u_L$，右侧坐标为 $u_R$。那么根据三角形 $\triangle P P_LP_R$ 和 $\triangle PO_LO_R$ 的相似关系，有：

$$\frac{P_LP_R}{O_LO_R} = \frac{b-u_L + u_R}{b} = \frac{z-f}{z}$$

稍加整理，得：
$$z = \frac{fb}{d}，d = u_L - u_R$$

这里 $d$ 为左右图的横坐标之差，称为 `视差（Disparity）`。根据视差，我们可以估计一个像素离相机的距离。视差与距离成反比：视差越大，距离越近。同时，由于视差最小为一个像素，于是双目的深度存在一个理论上的最大值，由 $fb$ 确定。我们看到，当基线越长时，双目最大能测到的距离就会变远；反之，小型双目器件则只能测量很近的距离。

虽然由视差计算深度的公式很简洁，但视差 $d$ 本身的计算却比较困难。我们需要确切地知道左眼图像某个像素出现在右眼图像的哪一个位置（即对应关系），这件事亦属于“人类觉得容易而计算机觉得困难”的事务。当我们想计算每个像素的深度时，其计算量与精度都将成为问题，而且只有在图像纹理变化丰富的地方才能计算视差。由于计算量的原因，双目深度估计仍需要使用 GPU 或 FPGA 来计算。这将在十三章中提到。



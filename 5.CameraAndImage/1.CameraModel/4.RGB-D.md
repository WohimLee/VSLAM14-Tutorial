&emsp;
# 1.4 RGB-D 相机模型

相比于双目相机通过视差计算深度的方式，RGB-D 相机的做法更为“主动”一些，它能够主动测量每个像素的深度。目前的 RGB-D 相机按原理可分为两大类：
- `通过红外结构光（Structured Light）`来测量像素距离的。例子有 Kinect 1 代、Project Tango 1 代、Intel RealSense 等；
- `通过飞行时间法（Time-of-flight, ToF）`原理测量像素距离的。例子有 Kinect 2 代和一些现有的 ToF 传感器等


<div align="center">
    <image src="./imgs/5.1.4-1.png" width = 700>
</div>
&emsp;


无论是结构光还是 ToF，RGB-D 相机都需要向探测目标发射一束光线（通常是红外光）。
- 在结构光原理中，相机根据返回的结构光图案，计算物体离自身的距离。
- 而在 ToF中，相机向目标发射脉冲光，然后根据发送到返回之间的光束飞行时间，确定物体离自身的距离。

ToF 原理和激光传感器十分相似，不过激光是通过逐点扫描来获取距离，而 ToF 相机则可以获得整个图像的像素深度，这也正是 RGB-D 相机的特点。所以，如果你把一个 RGB-D 相机拆开，通常会发现除了普通的摄像头之外，至少会有一个发射器和一个接收器。

在测量深度之后，RGB-D 相机通常按照生产时的各个相机摆放位置，自己完成深度与彩色图像素之间的配对，输出一一对应的彩色图和深度图。我们可以在同一个图像位置，读取到色彩信息和距离信息，计算像素的 3D 相机坐标，生成 `点云（Point Cloud）`。

对 RGB-D 数据，既可以在图像层面进行处理，亦可在点云层面处理。本讲的第二个实验将演示 RGB-D 相机的点云构建过程。

&emsp;
>RGB-D 相机的缺点
- RGB-D 相机能够实时地测量每个像素点的距离。但是，由于这种发射-接受的测量方式，使得它使用范围比较受限。
- 用红外进行深度值测量的 RGB-D 相机，容易受到日光或其他传感器发射的红外光干扰，因此不能在室外使用
- 同时使用多个时也会相互干扰。对于透射材质的物体，因为接受不到反射光，所以无法测量这些点的位置。
- 此外，RGB-D 相机在成本、功耗方面，都有一些劣势。
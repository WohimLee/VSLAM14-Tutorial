&emsp;
# 特征匹配

特征匹配 (如图 7-5 所示) 是视觉 SLAM 中极为关键的一步, 宽泛地说, 特征匹配解决了 SLAM 中的数据关联问题 (data association), 即确定当前看到的路标与之前看到的路标之间的对应关系。通过对图像与图像或者图像与地图之间的描述子进行准确匹配, 我们可以为后续的姿态估计、优化等操作减轻大量负担。然而, 由于图像特征的局部特性, 误匹配的情况广泛存在, 而且长期以来一直没有得到有效解决, 目前已经成为视觉 SLAM 中制约性能提升的一大瓶颈。部分原因是场景中经常存在大量的重复纹理，使得特征描述非常相似。在这种情况下，仅利用局部特征解决误匹配是非常困难的


不过, 让我们先来看正确匹配的情况, 等做完实验再回头去讨论误匹配问题。考虑两个时刻的图像。如果在图像 $I_t$ 中提取到特征点 $x_t^m, m=1,2, \ldots, M$, 在图像 $I_{t+1}$ 中提取到特征点 $x_{t+1}^n, n=$ $1,2, \ldots, N$, 如何寻找这两个集合元素的对应关系呢? 最简单的特征匹配方法就是暴力匹配（BruteForce Matcher)。即对每一个特征点 $x_t^m$ 与所有的 $x_{t+1}^n$ 测量描述子的距离, 然后排序, 取最近的一个作为匹配点。描述子距离表示了两个特征之间的相似程度, 不过在实际运用中还可以取不同的距离度量范数。对于浮点类型的描述子, 使用欧氏距离进行度量即可。而对于二进制的描述子 (比如 BRIEF 这样的), 我们往往使用汉明距离 (Hamming distance ) 作为度量一一两个二进制串之间的汉明距离, 指的是其不同位数的个数

然而, 当特征点数量很大时, 暴力匹配法的运算量将变得很大, 特别是当想要匹配某个帧和一张地图的时候。这不符合我们在 SLAM 中的实时性需求。此时快速近似最近邻 (FLANN) 算法更加适合于匹配点数量极多的情况。由于这些匹配算法理论已经成熟, 而且实现上也已集成到 OpenCV,所以这里就不再描述它的技术细节了。感兴趣的读者可以参考阅读文献 [47]

OpenCV 已经集成了多数主流的图像特征, 我们可以很方便地进行调用。下面我们来完成两个实验: 第一个实验中, 我们演示使用 OpenCV 进行 ORB 的特征匹配; 第二个实验中, 我们演示如何根据前面介绍的原理, 手写一个简单的 ORB 特征。通过手写的过程, 读者可以更加清楚地理解 $\mathrm{ORB}$ 的计算过程, 并类推到其他特征上去
